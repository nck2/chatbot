import os
from pathlib import Path
from langchain_community.document_loaders import PyMuPDFLoader
from langchain.embeddings import CacheBackedEmbeddings
# from langchain_community.embeddings import OpenAIEmbeddings
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI


from langchain_community.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.storage import LocalFileStore
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
# from langchain_community.chat_models import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler
import streamlit as st



# def get_api_key():
#     # st.secrets.getì€ None ë°˜í™˜í•˜ë¯€ë¡œ ì•ˆì „
#     cloud_key = st.secrets["OPENAI_API_KEY"]
#     if cloud_key:
#         return cloud_key

#     # ë¡œì»¬ìš© .env í™˜ê²½ ë³€ìˆ˜
#     from dotenv import load_dotenv
#     load_dotenv()
#     return os.getenv("OPENAI_API_KEY")


# api_key = get_api_key()



if "logged_in" not in st.session_state or not st.session_state.logged_in:
    st.error("ğŸš« ë¡œê·¸ì¸í•´ì•¼ ì‚¬ìš©ê°€ëŠ¥í•©ë‹ˆë‹¤. Home ìœ¼ë¡œ ê°€ì„¸ìš”.")
    # st.markdown("[Back to Login](./)")
    st.markdown("""
    <a href="./" target="_self">ğŸ”™ Homeìœ¼ë¡œ ê°€ì„œ ë¡œê·¸ì¸í•˜ê¸°</a>
""", unsafe_allow_html=True)

    st.stop()

# âœ… í´ë” ì•ˆì˜ ëª¨ë“  PDF ë¬¸ì„œë¥¼ ëŒ€ìƒ
STATIC_DIR = Path("./static/schoolviolence")

class ChatCallbackHandler(BaseCallbackHandler):
    message = ""
    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()
    def on_llm_end(self, *args, **kwargs):
        save_message(self.message, "ai")
    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)


llm = ChatOpenAI(
    temperature=0.1,
    streaming=True,
    callbacks=[ChatCallbackHandler()],

)

# âœ… ì—¬ëŸ¬ ë¬¸ì„œ ë¡œë”© & ë²¡í„° ìƒì„±
@st.cache_resource(show_spinner="ë¬¸ì„œ ë¡œë”©ì¤‘. ì ì‹œë§Œ ê¸°ë‹¤ë¦¬ì„¸ìš”...")
def load_all_documents():
    all_docs = []
    for file_path in STATIC_DIR.glob("*.pdf"):
        loader = PyMuPDFLoader(str(file_path))
        raw_docs = loader.load()

        # ê° ë¬¸ì„œì— file_name ì¶”ê°€
        for doc in raw_docs:
            doc.metadata["source"] = file_path.name

        splitter = CharacterTextSplitter.from_tiktoken_encoder(
            separator="\n", chunk_size=600, chunk_overlap=100,
        )
        chunks = splitter.split_documents(raw_docs)
        all_docs.extend(chunks)

    # ë²¡í„°í™”
    store = LocalFileStore(f"./.cache/embeddings/all_static/schoolviolence")
    embeddings = OpenAIEmbeddings()
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, store)
    vectorstore = FAISS.from_documents(all_docs, cached_embeddings)
    print("ğŸ“„ ë¬¸ì„œ ì„ë² ë”© ì‹¤í–‰ë¨")
    return vectorstore.as_retriever()

def save_message(message, role):
    st.session_state["messages1"].append({"message": message, "role": role})

def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)

def paint_history():
    for message in st.session_state["messages1"]:
        send_message(message["message"], message["role"], save=False)

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "Answer the question using ONLY the following context. If the answer is not found in the context below, reply in Korean with: 'ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' The information cannot be found in the document. DON'T make anything up.\n\nContext: {context}"),
        ("human", "{question}"),
    ]
)

# âœ… Streamlit ì‹œì‘
st.set_page_config(page_title="í•™êµí­ë ¥ì‚¬ì•ˆ ì±—ë´‡", page_icon="ğŸ“‚")
st.title("ğŸ“‚ í•™êµí­ë ¥ì‚¬ì•ˆ ì±—ë´‡")
st.markdown("##### ê°ì¢… í•™êµí­ë ¥ì‚¬ì•ˆì— ëŒ€í•´ ë¬¸ì„œ(**ì‚¬ì•ˆì²˜ë¦¬ê°€ì´ë“œë¶, ì•Œì“¸ì†Œì¤‘**)ë¥¼ ê·¼ê±°ë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤.")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages1" not in st.session_state:
    st.session_state["messages1"] = []



# ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
retriever = load_all_documents()
send_message("ëª¨ë“  ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸í•˜ì„¸ìš”.", "ai", save=False)
paint_history()

message = st.chat_input("Ask about the documents...")
if message:
    send_message(message, "human")
    # relevant_docs = retriever.get_relevant_documents(message)
    relevant_docs = retriever.invoke(message)


    chain = (
        {
            "context": lambda _: format_docs(relevant_docs),
            "question": RunnablePassthrough(),
        }
        | prompt
        | llm
    )

    with st.chat_message("ai"):
        chain.invoke(message)

    # âœ… ê° ë¬¸ì„œ + í˜ì´ì§€ ë²ˆí˜¸ í‘œì‹œ
    with st.expander("ğŸ” ì°¸ê³ ë¬¸í—Œ", expanded=False):
        for i, doc in enumerate(relevant_docs, start=1):
            source = doc.metadata.get("source", "Unknown")
            page = doc.metadata.get("page", "â“")
            st.markdown(f"**ë¬¸ì„œ {i} â€” ğŸ“„ `{source}` | Page {page+1}**")
            st.code(doc.page_content.strip(), language="markdown")
